# -*- coding: utf-8 -*-
"""Brain tumor Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M7BQp2KRekIS7eCuPdysrXObgdg4L6ty
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Convolution2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import Flatten
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import load_model



!wget https://www.dropbox.com/scl/fi/3u7vzedq0g3bkwv63oc4l/archive-4.zip?rlkey=5sopsc0a4xye6lmnwgznmfxwh&dl=0

!unzip /content/archive-4.zip?rlkey=5sopsc0a4xye6lmnwgznmfxwh

"""Data Analyze

Testing and Train Directories
"""

train_dir = '/content/Training'
testing_dir = '/content/Testing'

IMG_SIZE = 180

#Train DataSet
train_dataset = tf.keras.utils.image_dataset_from_directory(
  train_dir,
  validation_split = 0.2,
  subset = "training",
  seed = 123,
  image_size = (IMG_SIZE, IMG_SIZE),
  batch_size = 32)

#Validation DataSet
val_dataset = tf.keras.utils.image_dataset_from_directory(
    train_dir,
    validation_split = 0.2,
    subset = 'validation',
    seed = 123,
    image_size = (IMG_SIZE, IMG_SIZE),
    batch_size = 32)

class_names = train_dataset.class_names
class_names

"""Visualization Data"""

plt.figure(figsize=(10, 10)) #creating a new figure
for images, labels in train_dataset.take(1): # it iterate the 1st batch
  for i in range(9): # it give 9 images from the batch
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")

    #this is forr the basic generates a visual representation of the first 9 images in the train_dataset

"""AutoTune"""

AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)

val_dataset = val_dataset.cache().prefetch(buffer_size=AUTOTUNE)
#shuffeling is not need to validation data

"""Normalyze Data"""

#it normalize the image values in 1to 255 range to the 0 and 1 form

normalization_layer = layers.Rescaling(1./255)

data_augmentation = tf.keras.Sequential([
  tf.keras.layers.RandomFlip('horizontal', input_shape = (IMG_SIZE, IMG_SIZE, 3)),
  tf.keras.layers.RandomRotation(0.1),
  tf.keras.layers.RandomZoom(0.1) #randomly zoom in the direction of the horizonatl and vertical
])

"""Visualization Data"""

for image, _ in train_dataset.take(1):
  plt.figure(figsize=(10, 10))
  first_image = image[0]
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))
    plt.imshow(augmented_image[0] / 255)
    plt.axis('off')

"""Model"""

num_classes = len(class_names)#4

model = keras.Sequential([
    data_augmentation,
    normalization_layer,
    layers.Conv2D(16, 3, padding='same', activation='relu'),#convolution operation
    layers.MaxPooling2D(),#reduce dimention of the feature
    layers.Conv2D(32, 3, padding='same', activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(64, 3, padding='same', activation='relu'),
    layers.MaxPooling2D(),
    layers.Dropout(0.2),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),# no of neuron
    layers.Dense(num_classes, name="outputs")
])

"""Optimaze"""

model.compile(optimizer='adam',# adptive  moment estimation
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.summary()

"""Checkpoints"""

checkpoint_cb = keras.callbacks.ModelCheckpoint(
    'Brain_Tumor.h5'
)
# Early Stopping
early_stopping_cb = keras.callbacks.EarlyStopping(
    patience=10,
    restore_best_weights=True
)

epochs = 25
history = model.fit(
    train_dataset,
    validation_data=val_dataset,
    epochs=epochs,
    callbacks=[
        checkpoint_cb,
        early_stopping_cb
    ]
)

model.save('Brain_Tumor.h5')

epochs = len(history.epoch)
accuracy = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, accuracy, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

#Test DataSet
test_dataset = tf.keras.utils.image_dataset_from_directory(
  testing_dir,
  seed = 123,
  shuffle = True,
  image_size = (IMG_SIZE, IMG_SIZE),
  batch_size = 32)

predictions = model.predict(test_dataset)
scores = tf.nn.softmax(predictions[:])

for i in range(10):
    print(
        "This image most likely belongs to {} with a {:.2f} percent confidence."
        .format(class_names[np.argmax(scores[i])], 100 * np.max(scores[i]) - 5)
    )

scores = model.evaluate(test_dataset)
scores

"""Make a predictive system

"""

import numpy as np
from tensorflow.keras.preprocessing import image

# Load the trained model
model = tf.keras.models.load_model('Brain_Tumor.h5')

# Function to preprocess a single image
def preprocess_image(image_path):
    img = image.load_img(image_path, target_size=(180, 180))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    return img_array

# Function to make predictions
def predict_image(image_path):
    img_array = preprocess_image(image_path)
    prediction = model.predict(img_array)
    return prediction[0][0]

# Example usage
image_path = '/content/Testing/pituitary/Te-piTr_0000.jpg'
prediction = predict_image(image_path)
if prediction > 0.5:
    print('The image contains a brain tumor.')
else:
    print('The image does not contain a brain tumor.')

"""Saving the trained model"""

import pickle

filename = 'model_pikle.sav'
pickle.dump(model, open(filename, 'wb'))

# loading the saved model
loaded_model = pickle.load(open('model_pikle.sav', 'rb'))

import numpy as np
from tensorflow.keras.preprocessing import image

# Load the trained model
model = tf.keras.models.load_model('Brain_Tumor.h5')

# Function to preprocess a single image
def preprocess_image(image_path):
    img = image.load_img(image_path, target_size=(180, 180))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    return img_array

# Function to make predictions
def predict_image(image_path):
    img_array = preprocess_image(image_path)
    prediction = model.predict(img_array)
    return prediction[0][0]

# Example usage
image_path = '/content/Testing/pituitary/Te-piTr_0000.jpg'
prediction = predict_image(image_path)
if prediction > 0.5:
    print('The image contains a brain tumor.')
else:
    print('The image does not contain a brain tumor.')